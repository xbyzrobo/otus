{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(logs, tpe='loss'):\n",
    "    fig=plt.figure(figsize=(18, 9), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    for log in logs:\n",
    "        keys = log.keys()\n",
    "        logs = {k:[z for z in zip(*log[k])] for k in keys}\n",
    "        epochs = {k:range(len(log[k])) for k in keys}\n",
    "\n",
    "        if tpe == 'loss':\n",
    "            handlers, = zip(*[plt.plot(epochs[k], logs[k][0], label=k) for k in keys])\n",
    "            plt.title('errors')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('error')\n",
    "\n",
    "        elif tpe == 'accuracy':\n",
    "            handlers, = zip(*[plt.plot(epochs[k], logs[k][1], label=k) for k in log.keys()])\n",
    "            plt.title('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('accuracy')\n",
    "    plt.legend(handles=handlers)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.optim = optim.SGD(self.parameters(), lr=lr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models, log=None):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    train_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for k, model in models.items():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            train_loss[k] += loss.item() # sum up batch loss\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        print(line + losses)\n",
    "    for k in models:\n",
    "        train_loss[k] /= train_size\n",
    "    correct_pct = {k: 100. * correct[k] / train_size for k in correct}\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((train_loss[k], correct_pct[k]))\n",
    "    print(k, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'default': Net()}\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, loader, log=None):\n",
    "    test_size = len(loader.sampler)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # output = {k: m(data) for m in models}\n",
    "            for k, m in models.items():\n",
    "                output = m(data)\n",
    "                test_loss[k] += m.loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: 100. * correct[k] / test_size for k in correct}\n",
    "    lines = '\\n'.join([line(k, test_loss[k], correct[k], correct_pct[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLosses default: 2.368549\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLosses default: 2.354267\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLosses default: 2.353667\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLosses default: 2.329420\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLosses default: 2.340767\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLosses default: 2.314965\n",
      "Train Epoch: 1 [60000/60000 (100%)]\tLosses default: 2.309941\n",
      "default {'default': [(0.04650921772321065, 9.751666666666667)]}\n",
      "Test set:\n",
      "default: Loss: 2.3164\tAccuracy: 974.0/10000 (10%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLosses default: 2.381055\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLosses default: 2.288112\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLosses default: 2.327319\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLosses default: 2.285832\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLosses default: 2.273566\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLosses default: 2.318562\n",
      "Train Epoch: 2 [60000/60000 (100%)]\tLosses default: 2.308810\n",
      "default {'default': [(0.04650921772321065, 9.751666666666667), (0.04620472364028295, 9.753333333333334)]}\n",
      "Test set:\n",
      "default: Loss: 2.3064\tAccuracy: 975.0/10000 (10%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLosses default: 2.320333\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLosses default: 2.298846\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLosses default: 2.321635\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLosses default: 2.304193\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLosses default: 2.298509\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLosses default: 2.287642\n",
      "Train Epoch: 3 [60000/60000 (100%)]\tLosses default: 2.302631\n",
      "default {'default': [(0.04650921772321065, 9.751666666666667), (0.04620472364028295, 9.753333333333334), (0.0460694482088089, 11.72)]}\n",
      "Test set:\n",
      "default: Loss: 2.3017\tAccuracy: 1200.0/10000 (12%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLosses default: 2.298954\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLosses default: 2.293909\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLosses default: 2.303262\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLosses default: 2.295766\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLosses default: 2.296344\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLosses default: 2.303943\n",
      "Train Epoch: 4 [60000/60000 (100%)]\tLosses default: 2.297628\n",
      "default {'default': [(0.04650921772321065, 9.751666666666667), (0.04620472364028295, 9.753333333333334), (0.0460694482088089, 11.72), (0.0460046185652415, 11.308333333333334)]}\n",
      "Test set:\n",
      "default: Loss: 2.2992\tAccuracy: 1048.0/10000 (10%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLosses default: 2.291840\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLosses default: 2.303124\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLosses default: 2.303568\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 121):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models, train_log)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, test_loader, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test([train_log, test_log], 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
